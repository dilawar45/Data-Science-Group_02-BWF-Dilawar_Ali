{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Implement with TensorFlow/Keras (RNN)**"
      ],
      "metadata": {
        "id": "DsF7vg4ggLCH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **Data from Project Gutenberg**\n",
        "**\"Pride and Prejudice\" by Jane Austen**"
      ],
      "metadata": {
        "id": "kgHZ4OI5nHzL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# URL of the dataset\n",
        "url = \"https://www.gutenberg.org/files/1342/1342-0.txt\"\n",
        "response = requests.get(url)\n",
        "text_data = response.text\n",
        "\n",
        "# Preview the first 1000 characters\n",
        "print(text_data[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "gM20jCxBgv1m",
        "outputId": "5100f76c-5ca2-42f3-f08c-3d2026f04bb3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** START OF THE PROJECT GUTENBERG EBOOK 1342 ***\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "                            [Illustration:\r\n",
            "\r\n",
            "                             GEORGE ALLEN\r\n",
            "                               PUBLISHER\r\n",
            "\r\n",
            "                        156 CHARING CROSS ROAD\r\n",
            "                                LONDON\r\n",
            "\r\n",
            "                             RUSKIN HOUSE\r\n",
            "                                   ]\r\n",
            "\r\n",
            "                            [Illustration:\r\n",
            "\r\n",
            "               _Reading Janeâs Letters._      _Chap 34._\r\n",
            "                                   ]\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "                                PRIDE.\r\n",
            "                                  and\r\n",
            "                               PREJUDICE\r\n",
            "\r\n",
            "                                  by\r\n",
            "                             Jane Austen,\r\n",
            "\r\n",
            "                           with a Preface by\r\n",
            "                           George Saintsbury\r\n",
            "                                  and\r\n",
            "                           Illustrations by\r\n",
            "                             Hugh Thomson\r\n",
            "\r\n",
            "                         [Illustration: 1894]\r\n",
            "\r\n",
            "       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prepare Data**"
      ],
      "metadata": {
        "id": "iEbmIIY5nwl4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([text_data])\n",
        "\n",
        "# Convert text to sequences of integers\n",
        "sequences = tokenizer.texts_to_sequences([text_data])[0]\n",
        "\n",
        "# Create sequences and labels\n",
        "sequence_length = 5\n",
        "sequences_list = []\n",
        "labels_list = []\n",
        "\n",
        "for i in range(sequence_length, len(sequences)):\n",
        "    sequence = sequences[i-sequence_length:i]\n",
        "    label = sequences[i]\n",
        "    sequences_list.append(sequence)\n",
        "    labels_list.append(label)\n",
        "\n",
        "# Convert to numpy arrays\n",
        "X = np.array(sequences_list)\n",
        "y = np.array(labels_list)\n",
        "\n",
        "# One-hot encode the labels\n",
        "y = tf.keras.utils.to_categorical(y, num_classes=len(tokenizer.word_index) + 1)\n",
        "\n",
        "# Preview the sequences and labels\n",
        "print(X[:5])\n",
        "print(y[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "yIhoJHqIgwOX",
        "outputId": "feec8903-498f-4136-e92a-51d0f5df7399"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2804    4    2 2805 3520]\n",
            " [   4    2 2805 3520 3521]\n",
            " [   2 2805 3520 3521 3522]\n",
            " [2805 3520 3521 3522    1]\n",
            " [3520 3521 3522    1    1]]\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build Model**"
      ],
      "metadata": {
        "id": "EYbPZW0Tn04Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
        "\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=50, input_length=sequence_length))\n",
        "model.add(SimpleRNN(100, return_sequences=False))\n",
        "model.add(Dense(len(tokenizer.word_index) + 1, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "502YmpMwgwBU",
        "outputId": "a6498806-1c17-44bc-ff0d-4f967cd35e36"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 5, 50)             435450    \n",
            "                                                                 \n",
            " simple_rnn (SimpleRNN)      (None, 100)               15100     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 8709)              879609    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1330159 (5.07 MB)\n",
            "Trainable params: 1330159 (5.07 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training**"
      ],
      "metadata": {
        "id": "ZH2uBvbEmvR1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, y, epochs=20, batch_size=128, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "wRWGPt09hmog",
        "outputId": "1ed01123-8fce-44e0-ae7b-115bb7e50bdd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1055/1055 [==============================] - 35s 30ms/step - loss: 6.5311 - accuracy: 0.0577\n",
            "Epoch 2/20\n",
            "1055/1055 [==============================] - 14s 13ms/step - loss: 5.7250 - accuracy: 0.1136\n",
            "Epoch 3/20\n",
            "1055/1055 [==============================] - 14s 13ms/step - loss: 5.3347 - accuracy: 0.1376\n",
            "Epoch 4/20\n",
            "1055/1055 [==============================] - 14s 13ms/step - loss: 5.0843 - accuracy: 0.1529\n",
            "Epoch 5/20\n",
            "1055/1055 [==============================] - 14s 13ms/step - loss: 4.8846 - accuracy: 0.1643\n",
            "Epoch 6/20\n",
            "1055/1055 [==============================] - 14s 13ms/step - loss: 4.7114 - accuracy: 0.1742\n",
            "Epoch 7/20\n",
            "1055/1055 [==============================] - 14s 13ms/step - loss: 4.5536 - accuracy: 0.1841\n",
            "Epoch 8/20\n",
            "1055/1055 [==============================] - 14s 13ms/step - loss: 4.4056 - accuracy: 0.1944\n",
            "Epoch 9/20\n",
            "1055/1055 [==============================] - 14s 13ms/step - loss: 4.2662 - accuracy: 0.2057\n",
            "Epoch 10/20\n",
            "1055/1055 [==============================] - 15s 14ms/step - loss: 4.1315 - accuracy: 0.2192\n",
            "Epoch 11/20\n",
            "1055/1055 [==============================] - 14s 13ms/step - loss: 4.0021 - accuracy: 0.2333\n",
            "Epoch 12/20\n",
            "1055/1055 [==============================] - 14s 13ms/step - loss: 3.8802 - accuracy: 0.2466\n",
            "Epoch 13/20\n",
            "1055/1055 [==============================] - 13s 13ms/step - loss: 3.7626 - accuracy: 0.2631\n",
            "Epoch 14/20\n",
            "1055/1055 [==============================] - 14s 13ms/step - loss: 3.6512 - accuracy: 0.2788\n",
            "Epoch 15/20\n",
            "1055/1055 [==============================] - 13s 13ms/step - loss: 3.5440 - accuracy: 0.2949\n",
            "Epoch 16/20\n",
            "1055/1055 [==============================] - 13s 12ms/step - loss: 3.4430 - accuracy: 0.3085\n",
            "Epoch 17/20\n",
            "1055/1055 [==============================] - 14s 13ms/step - loss: 3.3480 - accuracy: 0.3244\n",
            "Epoch 18/20\n",
            "1055/1055 [==============================] - 14s 13ms/step - loss: 3.2557 - accuracy: 0.3394\n",
            "Epoch 19/20\n",
            "1055/1055 [==============================] - 13s 13ms/step - loss: 3.1707 - accuracy: 0.3531\n",
            "Epoch 20/20\n",
            "1055/1055 [==============================] - 14s 13ms/step - loss: 3.0894 - accuracy: 0.3676\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7df9ec9357b0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Below Paragraph is taken from the from the book for test purose (to check the prediction of next word)**."
      ],
      "metadata": {
        "id": "75NHLPfmoIYV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I think, however, though the thought will doubtless seem heretical to\n",
        "more than one school of critics, that construction is not the highest\n",
        "merit, the choicest gift, of the novelist. __It sets off his other gifts\n",
        "and graces most advantageously to the__ critical eye; and the want of it\n",
        "will sometimes mar those graces--appreciably, though not quite\n",
        "consciously--to eyes by no means ultra-critical. But a very badly-built\n",
        "novel which excelled in pathetic or humorous character, or which\n",
        "displayed consummate command of dialogue--perhaps the rarest of all\n",
        "faculties--would be an infinitely better thing than a faultless plot\n",
        "acted and told by puppets with pebbles in their mouths. And despite the\n",
        "ability which Miss Austen has shown in working out the story, I for one\n",
        "should put_ Pride and Prejudice _far lower if it did not contain what\n",
        "seem to me the very masterpieces of Miss Austenâ€™s humour and of her\n",
        "faculty of character-creation--masterpieces who may indeed admit John\n",
        "Thorpe, the Eltons, Mrs. Norris, and one or two others to their company,\n",
        "but who, in one instance certainly, and perhaps in others, are still\n",
        "superior to them."
      ],
      "metadata": {
        "id": "E4jdSwmqmRV6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generate Text**"
      ],
      "metadata": {
        "id": "6hf1jA64n9q4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word(model, tokenizer, text, sequence_length):\n",
        "    # Tokenize the input text\n",
        "    sequence = tokenizer.texts_to_sequences([text])[0]\n",
        "    sequence = pad_sequences([sequence], maxlen=sequence_length, truncating='pre')\n",
        "\n",
        "    # Predict the next word\n",
        "    predicted = np.argmax(model.predict(sequence), axis=-1)\n",
        "\n",
        "    # Convert the predicted integer back to a word\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == predicted:\n",
        "            return word\n",
        "    return None\n",
        "\n",
        "# Highlighted Text is taken from above para to predict the next word\n",
        "seed_text = \" It sets off his other gifts and graces most advantageously to the\"\n",
        "next_word = predict_next_word(model, tokenizer, seed_text, sequence_length)\n",
        "print(f\"Seed text: {seed_text}\")\n",
        "print(f\"Predicted next word: {next_word}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_VQ7GxNhoWU",
        "outputId": "6e60cae2-9ac6-460a-926f-a0ed6b7ce28b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 25ms/step\n",
            "Seed text:  It sets off his other gifts and graces most advantageously to the\n",
            "Predicted next word: critical\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gk_phMUymAw7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}