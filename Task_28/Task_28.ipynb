{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Task_28**"
      ],
      "metadata": {
        "id": "_xk3wNbSd6SN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sh6sp_P8d2Dr"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Titanic dataset\n",
        "titanic = sns.load_dataset('titanic')"
      ],
      "metadata": {
        "id": "ctvBawPfeCpf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows with missing values in relevant columns\n",
        "titanic = titanic.dropna(subset=['age', 'sex', 'fare', 'class', 'embarked', 'survived'])\n",
        "\n"
      ],
      "metadata": {
        "id": "gJPW5pMneCmK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert categorical features to numerical\n",
        "titanic['sex'] = titanic['sex'].map({'male': 0, 'female': 1})\n",
        "titanic['class'] = titanic['class'].map({'First': 1, 'Second': 2, 'Third': 3})\n",
        "titanic['embarked'] = titanic['embarked'].map({'C': 0, 'Q': 1, 'S': 2})\n"
      ],
      "metadata": {
        "id": "qPfAQVWEeCkA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define features and target variable\n",
        "X = titanic[['age', 'sex', 'fare', 'class', 'embarked']]\n",
        "y = titanic['survived']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
      ],
      "metadata": {
        "id": "40588zXoeChu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "hDIciGdJeCZK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Cross-Validation**"
      ],
      "metadata": {
        "id": "KrPh_X8mgVjK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Train a logistic regression model\n",
        "model = LogisticRegression()\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_scores = cross_val_score(model, X_train, y_train, cv=5)\n",
        "print(\"Cross-Validation Scores:\", cv_scores)\n",
        "print(\"Mean Cross-Validation Score:\", cv_scores.mean())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhKE2aN7gWFP",
        "outputId": "c678f0c3-fcbd-47f0-9d79-d4445df43cc6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation Scores: [0.71       0.85       0.84       0.76767677 0.80808081]\n",
            "Mean Cross-Validation Score: 0.7951515151515152\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cross-Validation:** Helps in assessing the generalization ability of the model"
      ],
      "metadata": {
        "id": "9wr97worhE_e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Overfitting**"
      ],
      "metadata": {
        "id": "x4u7tokAgib4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Train a more complex model (Random Forest)\n",
        "complex_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "complex_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate on training set\n",
        "train_score = complex_model.score(X_train, y_train)\n",
        "print(\"Training Score (Random Forest):\", train_score)\n",
        "\n",
        "# Evaluate on testing set\n",
        "test_score = complex_model.score(X_test, y_test)\n",
        "print(\"Testing Score (Random Forest):\", test_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGm5KGbZgiz3",
        "outputId": "9d83ff06-37c9-4dac-8918-2cee2644aa85"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Score (Random Forest): 0.9919678714859438\n",
            "Testing Score (Random Forest): 0.7616822429906542\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Overfitting:**Demonstrated by a complex model (Random Forest) performing significantly better on the training set than on the testing set."
      ],
      "metadata": {
        "id": "J3QracYnhPE_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Underfitting**"
      ],
      "metadata": {
        "id": "4VcJdJ80g0XT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Train a simpler model (Decision Tree with max depth 1)\n",
        "simple_model = DecisionTreeClassifier(max_depth=1, random_state=42)\n",
        "simple_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate on training set\n",
        "train_score_simple = simple_model.score(X_train, y_train)\n",
        "print(\"Training Score (Decision Tree):\", train_score_simple)\n",
        "\n",
        "# Evaluate on testing set\n",
        "test_score_simple = simple_model.score(X_test, y_test)\n",
        "print(\"Testing Score (Decision Tree):\", test_score_simple)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwR2R0iog0Di",
        "outputId": "212c0f3f-3fb2-4412-9426-be1a01c2df25"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Score (Decision Tree): 0.7911646586345381\n",
            "Testing Score (Decision Tree): 0.7523364485981309\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Underfitting:** Demonstrated by a simple model (Decision Tree with max depth 1) performing poorly on both the training set and the testing set"
      ],
      "metadata": {
        "id": "ZN6XLLcwhWnz"
      }
    }
  ]
}