{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Task_25**\n",
        "# Regression Model from scratch"
      ],
      "metadata": {
        "id": "YYIT3LjjlYaS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Define the Sigmoid Function**"
      ],
      "metadata": {
        "id": "YPw1guj7kzS2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "POkDvF8wkEz6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Implement the Cost Function (Cross-Entropy)**"
      ],
      "metadata": {
        "id": "jcCUKM95k6K_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_cost(X, y, weights):\n",
        "    m = len(y)\n",
        "    h = sigmoid(X.dot(weights))\n",
        "    epsilon = 1e-5\n",
        "    cost = -(1/m) * (y.T.dot(np.log(h + epsilon)) + (1 - y).T.dot(np.log(1 - h + epsilon)))\n",
        "    return cost"
      ],
      "metadata": {
        "id": "OaCsSKgtkMtL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Implement Gradient Descent for Optimization**"
      ],
      "metadata": {
        "id": "MARslZrkk_0B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(X, y, weights, learning_rate, num_iterations):\n",
        "    m = len(y)\n",
        "    cost_history = np.zeros(num_iterations)\n",
        "\n",
        "    for i in range(num_iterations):\n",
        "        h = sigmoid(X.dot(weights))\n",
        "        weights -= learning_rate * (1/m) * X.T.dot(h - y)\n",
        "        cost_history[i] = compute_cost(X, y, weights)\n",
        "\n",
        "    return weights, cost_history\n"
      ],
      "metadata": {
        "id": "kywFKNDzkNtc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Train the Model**"
      ],
      "metadata": {
        "id": "VQZAC2IWlEqk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the Titanic dataset\n",
        "titanic = sns.load_dataset('titanic')\n",
        "\n",
        "# Drop rows with missing values in relevant columns\n",
        "titanic = titanic.dropna(subset=['age', 'sex', 'fare', 'class', 'embarked', 'survived'])\n",
        "\n",
        "# Convert categorical features to numerical\n",
        "titanic['sex'] = titanic['sex'].map({'male': 0, 'female': 1})\n",
        "titanic['class'] = titanic['class'].map({'First': 1, 'Second': 2, 'Third': 3})\n",
        "titanic['embarked'] = titanic['embarked'].map({'C': 0, 'Q': 1, 'S': 2})"
      ],
      "metadata": {
        "id": "2P1RGnXIkNrh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define features and target variable\n",
        "X = titanic[['age', 'sex', 'fare', 'class', 'embarked']]\n",
        "y = titanic['survived']\n",
        "\n",
        "# Add intercept term to X\n",
        "X = np.c_[np.ones((X.shape[0], 1)), X]\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
      ],
      "metadata": {
        "id": "2-jWmm4UkNpa"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize the features (excluding the intercept term)\n",
        "scaler = StandardScaler()\n",
        "X_train[:, 1:] = scaler.fit_transform(X_train[:, 1:])\n",
        "X_test[:, 1:] = scaler.transform(X_test[:, 1:])\n",
        "\n",
        "# Initialize weights\n",
        "weights = np.zeros(X_train.shape[1])\n",
        "\n",
        "# Set hyperparameters\n",
        "learning_rate = 0.01\n",
        "num_iterations = 10000\n",
        "\n",
        "# Train the model using gradient descent\n",
        "weights, cost_history = gradient_descent(X_train, y_train, weights, learning_rate, num_iterations)\n"
      ],
      "metadata": {
        "id": "J_L1ZWC2kNnR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Evaluate the Model**"
      ],
      "metadata": {
        "id": "EHkjefbzlOAp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(X, weights):\n",
        "    return sigmoid(X.dot(weights)) >= 0.5\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = predict(X_test, weights)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = np.mean(y_pred == y_test)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQtvDLD8kNlS",
        "outputId": "0428b757-9541-4b30-f520-eb86b19be6d5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7850467289719626\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uqxsYZQckNis"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}